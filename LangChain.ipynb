{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Settings\n",
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.agents import create_csv_agent\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Environment Variables for Azure OpenAI Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"apikey\")\n",
    "BASE_ENDPOINT = os.getenv(\"api_base\")\n",
    "COMPLETION_MODEL = os.getenv(\"completion_model\")\n",
    "CHAT_MODEL = os.getenv(\"chat_model\")\n",
    "EMBEDDING_MODEL = os.getenv(\"embedding_model\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"api_version\")\n",
    "\n",
    "#init Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = DEPLOYMENT_VERSION\n",
    "openai.api_base = BASE_ENDPOINT\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalizing Azure OpenAI Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Davinci Model for text completion \n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=COMPLETION_MODEL ,\n",
    "    openai_api_key= API_KEY ,openai_api_version =DEPLOYMENT_VERSION\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this format for Chatgpt or GPT4\n",
    "gptchat = AzureChatOpenAI(\n",
    "    deployment_name=CHAT_MODEL,\n",
    "    openai_api_base = BASE_ENDPOINT,\n",
    "    openai_api_key= API_KEY,\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q: Why don't scientists trust atoms?\n",
      "A: Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "joke = llm(\"Tell me a dad joke\")\n",
    "print(joke)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chat Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I cannot give real-time data, but the top movie trends in the US usually include superhero films, remakes or reboots, animated movies, adaptations of bestselling books, and streaming platform originals. Be sure to check the latest box office charts and streaming platforms for current trends.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gptchat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an AI assistant that helps a user with marketing content. Keep responses short and under 5 sentences.\"),\n",
    "        HumanMessage(content=\"What are top movie trends in US\")\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1536\n",
      "[0.009326309897005558, -0.0006310197059065104, 0.006163125857710838, -0.015400114469230175, -0.013527460396289825]\n"
     ]
    }
   ],
   "source": [
    "openai_embed = OpenAIEmbeddings(model=EMBEDDING_MODEL,\n",
    "                                openai_api_key=API_KEY)\n",
    "\n",
    "query_embeddings = openai_embed.embed_query(\"The sky is blue\") \n",
    "\n",
    "print(type(query_embeddings))\n",
    "print(len(query_embeddings))\n",
    "print(query_embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Prompt Templates for use input and capturing any variables / non static informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PROMPT: Write a small advertisement a new Headphones and its description Best headphones?\n",
      " Look no further!\n",
      "\n",
      "Introducing the latest and greatest in sound technology: the G-Power Headphones. With superior sound quality and a comfortable fit, these headphones are the perfect addition to any music lover's collection. Featuring noise-cancelling technology and a long-lasting battery life, the G-Power Headphones deliver exceptional sound for an unbeatable price. Enjoy your favorite tunes with crystal clear clarity and deep bass. Get the G-Power Headphones today and experience the ultimate in audio quality.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template with placeholders for input variables.\n",
    "prompt_template = PromptTemplate(\n",
    "        template = 'Write a small advertisement a new {product} and its description {product_desc}?',\n",
    "        input_variables = ['product', 'product_desc']\n",
    ")\n",
    "\n",
    "# Create the final prompt by filling in the defined variables.\n",
    "final_prompt = prompt_template.format(product='Headphones',  product_desc='Best headphones')\n",
    "print(\"FINAL PROMPT: \" + final_prompt)\n",
    "\n",
    "response = llm(final_prompt) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Introducing the new Electric Vehicle from Iceland – the perfect choice for your next green adventure! This vehicle has a range of up to 200 miles on a single charge, and a top speed of 80 mph. It is designed to handle the rugged terrain of Iceland's roads with ease, and is equipped with advanced safety features to help keep you and your passengers safe. Plus, the Electric Vehicle from Iceland helps reduce your carbon footprint and is eligible for various tax credits and incentives. Get ready to explore Iceland in style – with the Electric Vehicle from Iceland!\n"
     ]
    }
   ],
   "source": [
    "# Reuse the prompt Template\n",
    "print(llm(prompt_template.format(product ='Electric Vehicle', product_desc='Iceland')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the schema\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"product\", description=\"This is a product\"),\n",
    "    ResponseSchema(name=\"product_desc\", description=\"This is a short description of the product\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"product\": string  // This is a product\n",
      "\t\"product_desc\": string  // This is a short description of the product\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 2. Generates output format instructions which can be included in your prompt.\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PROMPT:\n",
      "\n",
      "You will be given a product by the user.\n",
      "Please provide a imaginary, creative and non offensive product name and a short description of the product.\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"product\": string  // This is a product\n",
      "\t\"product_desc\": string  // This is a short description of the product\n",
      "}\n",
      "```\n",
      "\n",
      "% PRODUCT:\n",
      "Iphone\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Incorporate into final prompt.\n",
    "\n",
    "template = '''\n",
    "You will be given a product by the user.\n",
    "Please provide a imaginary, creative and non offensive product name and a short description of the product.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% PRODUCT:\n",
    "{product}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(product=\"Iphone\")\n",
    "print('FINAL PROMPT:')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"product\": \"Iphone\",\n",
      "\t\"product_desc\": \"The ultimate smartphone for the modern user, with an intuitive interface and a sleek design.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 4. LLM now outputs an easily parsable response.\n",
    "\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ultimate smartphone for the modern user, with an intuitive interface and a sleek design.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Output parser can extract named fields in the schema.\n",
    "\n",
    "output_parser.parse(response)['product_desc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain component 1: \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "template1 = \"\"\"You will be given an error from the user. Please provide a possible solution.\n",
    "\n",
    "% ERROR\n",
    "{error}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(input_variables=[\"error\"], template=template1)\n",
    "\n",
    "# LLMChain is a simple chain which takes a prompt template, formats with user input and returns LLM output.\n",
    "error_chain = LLMChain(llm=llm, prompt=prompt_template1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain component 2: \n",
    "\n",
    "template2 = \"\"\"Given the error message, provide a short solution for fixing it.\n",
    "\n",
    "% MESSAGE\n",
    "{message}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"message\"], template=template2)\n",
    "\n",
    "message_chain = LLMChain(llm=llm, prompt=prompt_template2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThis error occurs when you attempt to divide a number by zero. To fix it, make sure that you are not dividing by zero. If you need to, you can use an if statement to check if the denominator is equal to zero before attempting the division.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mTo fix this error, make sure to check if the denominator is equal to zero before attempting the division. You can use an if statement to check if the denominator is equal to zero and then take the appropriate action if it is.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[error_chain, message_chain],\n",
    "    verbose=True)\n",
    "chain_output = overall_chain.run(\"ZeroDivisionError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fix this error, make sure to check if the denominator is equal to zero before attempting the division. You can use an if statement to check if the denominator is equal to zero and then take the appropriate action if it is.\n"
     ]
    }
   ],
   "source": [
    "print(chain_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document loader & text splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of The Merchant of Venice, by William Shakespeare\n",
      "Document length in characters: 154162\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import GutenbergLoader\n",
    "\n",
    "# Load a long document.\n",
    "loader = GutenbergLoader('https://www.gutenberg.org/cache/epub/1515/pg1515.txt')\n",
    "doc = loader.load()\n",
    "\n",
    "print(doc[0].page_content[:80].rstrip())\n",
    "print('Document length in characters:', len(doc[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE PRINCE OF MOROCCO, suitor to Portia\\r\\n\\n\\nTHE PRINCE OF ARRAGON, suitor to Portia\\r\\n\\n\\nANTONIO, a merchant of Venice\\r\\n\\n\\nBASSANIO, his friend, suitor to Portia\\r\\n\\n\\nGRATIANO, friend to Antonio and Bassanio\\r\\n\\n\\nSOLANIO, friend to Antonio and Bassanio\\r\\n\\n\\nSALARINO, friend to Antonio and Bassanio\\r\\n\\n\\nLORENZO, in love with Jessica\\r\\n\\n\\nSHYLOCK, a rich Jew\\r\\n\\n\\nTUBAL, a Jew, his friend\\r\\n\\n\\nLAUNCELET GOBBO, a clown, servant to Shylock\\r\\n\\n\\nOLD GOBBO, father to Launcelet\\r\\n\\n\\nLEONARDO, servant to Bassanio\\r\\n\\n\\nBALTHAZAR, servant to Portia\\r\\n\\n\\nSTEPHANO, servant to Portia\\r\\n\\n\\nSALERIO, a messenger from Venice\\r\\n\\n\\n\\r\\n\\n\\nPORTIA, a rich heiress\\r\\n\\n\\nNERISSA, her waiting-woman\\r\\n\\n\\nJESSICA, daughter to Shylock\\r\\n\\n\\n\\r\\n\\n\\nMagnificoes of Venice, Officers of the Court of Justice, a Gaoler,\\r\\n\\n\\nServants and other Attendants\\r\\n\\n\\n\\r\\n\\n\\nSCENE: Partly at Venice, and partly at Belmont, the seat of Portia on\\r\\n\\n\\nthe Continent\\r\\n\\n\\n\\r\\n\\n\\n\\r\\n\\n\\n\\r\\n\\n\\n\\r\\n\\n\\nACT I\\r\\n\\n\\n\\r\\n\\n\\nSCENE I. Venice. A street.\\r\\n\\n\\n\\r\\n\\n\\n\\r\\n\\n\\n Enter Antonio, Salarino and Solanio.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# We need to split long documents into smaller chunks to stay under the LLM token limit.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(doc[0].page_content)\n",
    "texts[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "#### CSV Agent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(llm, 'goalies17.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the difference between the two players' saved shots\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df['Player'] == 'Martin Houle']['Saves'].values[0] - df[df['Player'] == 'Adam']['Saves'].values[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndexError: index 0 is out of bounds for axis 0 with size 0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the player Adam\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df['Player'].str.contains('Adam')]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m            Player  First  Last  Active  Games Played  Games Started  Win  \\\n",
      "11     Adam Hauser   2005  2006       1             1            NaN  0.0   \n",
      "183  Adam Berkhoel   2005  2006       1             9            NaN  2.0   \n",
      "209     Adam Munro   2003  2006       2            17            NaN  4.0   \n",
      "681     John Adams   1972  1975       2            22            NaN  9.0   \n",
      "\n",
      "     Loss  Ties and Overtime Losses  Goals Against  Shot Saved  Saves  \\\n",
      "11    0.0                       0.0              6        24.0   18.0   \n",
      "183   4.0                       1.0             30       255.0  225.0   \n",
      "209  10.0                       3.0             51       451.0  400.0   \n",
      "681  10.0                       1.0             85         NaN    NaN   \n",
      "\n",
      "     Save Percentage  Goals Against Average  Shutouts  Penalties In Minutes  \\\n",
      "11             0.750                   7.06         0                     0   \n",
      "183            0.882                   3.81         0                     0   \n",
      "209            0.887                   3.30         1                     2   \n",
      "681              NaN                   4.32         1                     2   \n",
      "\n",
      "     Minutes  \n",
      "11        51  \n",
      "183      473  \n",
      "209      927  \n",
      "681     1180  \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the difference between the two players' saved shots\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df['Player'] == 'Martin Houle']['Saves'].values[0] - df[df['Player'] == 'Adam Hauser']['Saves'].values[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m-16.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Martin Houle saved 16 more shots than Adam Hauser.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Martin Houle saved 16 more shots than Adam Hauser.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many more shots did player Martin saved than adam?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + Coversation Chain and  Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Green, blue, indigo, violet.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a converation chain\n",
    "conversation = ConversationChain(\n",
    "    llm=gptchat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.run(\"Answer briefly. What are the first 3 colors of a rainbow?\")\n",
    "# -> The first three colors of a rainbow are red, orange, and yellow.\n",
    "conversation.run(\"And the next 4?\")\n",
    "# -> The next four colors of a rainbow are green, blue, indigo, and violet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a article generation tool that generates articles for\\\n",
    "            car Brand. Use title similar to Number of Tips from Pros to Make Your vehicle perform the best.\\\n",
    "            The content should use details keywords and explain and extend them and use {content}. \\\n",
    "            The word count of the article should be minimum 1000 words\n",
    "            {chat_history}\n",
    "            Human: {content}\n",
    "            Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"content\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=gptchat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a article generation tool that generates articles for            car Brand. Use title similar to Number of Tips from Pros to Make Your vehicle perform the best.            The content should use details keywords and explain and extend them and use Write an introductory paragraph that gives context to the reader, introducing the overall theme of the article. Try to include the target keywords.             The word count of the article should be minimum 1000 words\n",
      "            \n",
      "            Human: Write an introductory paragraph that gives context to the reader, introducing the overall theme of the article. Try to include the target keywords\n",
      "            Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "intro_text = llm_chain.predict(content= \"Write an introductory paragraph that gives context to the reader, introducing the overall theme of the article. Try to include the target keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In today's fast-paced world, car enthusiasts and everyday drivers alike are constantly seeking ways to optimize their vehicle's performance. This article is your ultimate guide to unlocking your car's full potential, as we bring you a comprehensive list of tips from the pros to make your vehicle perform at its best. Whether you're driving a luxury car or a budget-friendly option, our expert advice and detailed keywords will steer you in the right direction to achieve peak performance on the road. Get ready to rev up your engine and embark on a journey towards enhancing your driving experience with our top-notch recommendations.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a article generation tool that generates articles for            car Brand. Use title similar to Number of Tips from Pros to Make Your vehicle perform the best.            The content should use details keywords and explain and extend them and use Discuss how car should be kept clean, well serviced and well maintained.             The word count of the article should be minimum 1000 words\n",
      "            Human: Write an introductory paragraph that gives context to the reader, introducing the overall theme of the article. Try to include the target keywords\n",
      "AI: In today's fast-paced world, car enthusiasts and everyday drivers alike are constantly seeking ways to optimize their vehicle's performance. This article is your ultimate guide to unlocking your car's full potential, as we bring you a comprehensive list of tips from the pros to make your vehicle perform at its best. Whether you're driving a luxury car or a budget-friendly option, our expert advice and detailed keywords will steer you in the right direction to achieve peak performance on the road. Get ready to rev up your engine and embark on a journey towards enhancing your driving experience with our top-notch recommendations.\n",
      "            Human: Discuss how car should be kept clean, well serviced and well maintained\n",
      "            Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "content_1 = llm_chain.predict(content= \"Discuss how car should be kept clean, well serviced and well maintained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A clean, well-serviced, and well-maintained car is not only aesthetically pleasing but is also crucial for optimal performance, safety, and longevity. Here are some key aspects you should focus on to ensure your vehicle stays in top condition:\\n\\n1. Regular car washes: Keeping your car clean not only enhances its appearance but also prevents dirt, grime, and other contaminants from causing damage to the paintwork and other components. Washing your car regularly, using a high-quality car shampoo and microfiber cloths, can help maintain its shine and protect the finish.\\n\\n2. Waxing and polishing: Applying a quality wax or polish can create a protective barrier on your car's paintwork, shielding it from the harsh effects of the sun, rain, and other environmental factors. Waxing and polishing also help keep your car looking new and glossy, while minimizing the risk of scratches and swirl marks.\\n\\n3. Interior cleaning: A clean interior not only contributes to a more enjoyable driving experience but also helps maintain the value of your car. Regularly vacuum the carpets, wipe down surfaces with a damp cloth, and use appropriate cleaners for leather and upholstery. Don't forget to clean air vents and replace the cabin air filter to ensure a healthy and pleasant environment inside your vehicle.\\n\\n4. Regular servicing: Adhering to your car's recommended maintenance schedule is essential for keeping it in top shape and ensuring optimal performance. Regular servicing, including oil changes, filter replacements, and fluid top-ups, can prevent potential issues and costly repairs down the line. Make sure to consult your owner's manual for guidance on the suggested service intervals for your specific vehicle.\\n\\n5. Tire maintenance: Tires play a vital role in your vehicle's performance, safety, and fuel efficiency. Regularly inspect your tires for signs of wear, check the tire pressure, and rotate them as advised by the manufacturer to ensure even wear and optimal handling. Don't forget to have your wheels aligned and balanced to minimize vibrations and uneven tire wear.\\n\\n6. Brake system maintenance: Your car's braking system is a critical safety component, and regular maintenance is crucial to ensure its proper functioning. Inspect brake pads, rotors, and fluid levels regularly and replace or service them as needed to guarantee optimal stopping power and safety on the road.\\n\\n7. Cooling system maintenance: An efficient cooling system is essential to prevent overheating and maintain the overall performance of your car. Regularly check the coolant level, inspect hoses and belts for signs of wear, and flush the system periodically to keep it running smoothly.\\n\\n8. Battery care: A well-maintained battery is crucial for the optimal performance of your vehicle's electrical system. Regularly check the battery terminals for signs of corrosion, clean them as needed, and inspect the battery's charge to ensure it's functioning correctly. Replacing your battery according to the manufacturer's recommended lifespan can help prevent unexpected breakdowns and electrical issues.\\n\\n9. Suspension and steering components: Regularly inspect your car's suspension and steering systems to identify any worn or damaged parts that may affect your vehicle's ride quality and handling. Timely replacements and repairs can enhance your driving experience and ensure a safer journey.\\n\\n10. Keep records: Maintain a detailed log of all the services, repairs, and maintenance work performed on your car. This will not only help you track your vehicle's upkeep but also add value when it comes time to sell or trade-in.\\n\\nIn conclusion, keeping your car clean, well-serviced, and well-maintained is vital to ensure its optimal performance, safety, and longevity. By following the tips outlined above and adhering to your vehicle's recommended maintenance schedule, you can enjoy a smooth and hassle-free driving experience while protecting your investment.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
